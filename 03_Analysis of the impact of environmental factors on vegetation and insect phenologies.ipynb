{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2136f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load package\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pingouin as pg\n",
    "import os,shutil\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e510077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data match\n",
    "# Batch obtain data from .npy environmental data files in a folder\n",
    "def list_npy_files(root_dir, npy_list):\n",
    "    # Use glob to find all .npy files in the directory and its subdirectories\n",
    "    npy_files = glob.glob(os.path.join(root_dir, '.../julian/*.npy'), recursive=True)\n",
    "    npy_list.extend(npy_files)\n",
    "\n",
    "# Initialize an empty list\n",
    "list_npy = []\n",
    "\n",
    "# Store result in list_csv\n",
    "list_npy_files(r\"...:\\Environmental_factors_file_path\", list_npy) #Modified to the path where environmental factors are stored \n",
    "\n",
    "# Read the phenology records\n",
    "df = pd.read_hdf('..../pts.h5', key='data')\n",
    "df = df.reset_index()\n",
    "\n",
    "# Match phenological data and environmental factor data\n",
    "for file in list_npy:\n",
    "    fpath,fname=os.path.split(file)\n",
    "    fname = fname.split('.')[0]\n",
    "    env = np.load(file)\n",
    "    # Creat DataFrame\n",
    "    env=pd.DataFrame(env)\n",
    "    # Calculate the average environmental factors between 0 and 6 months\n",
    "    env2 = np.cumsum(env, axis=1) / (np.arange(7)+1)\n",
    "    # Add the specified column name to the column\n",
    "    columns = [fname+'_{}'.format(i) for i in range(0, 7)]\n",
    "    env2.columns = columns\n",
    "    df = df.join(env2)\n",
    "\n",
    "# Adding the column order_cluster facilitates subsequent analysis\n",
    "df = df.assign(species_cluster=df['species'].astype(str) + '_' + df['cate'].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07da9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using linear regression to remove annual trends\n",
    "def remove_annual_trends(data, column):\n",
    "    X = data['year'].astype('float64')\n",
    "    y = data[column].astype('float64')\n",
    "    model = OLS(y, sm.add_constant(X))\n",
    "    results = model.fit()\n",
    "    y_residual = results.resid\n",
    "    return y_residual\n",
    "\n",
    "\n",
    "# Optimal Pre-Season Selection\n",
    "# Using linear regression to remove annual trends\n",
    "def calculate_most_influential_column(factor, filtered_df1):\n",
    "    # Create a dictionary to store the partial correlation coefficients for each factor column\n",
    "    partial_corr = {}\n",
    "    # Calculate the partial correlation coefficient for each factor column\n",
    "    for i in range(7):\n",
    "        column_name = factor + str(i)\n",
    "        filtered_df1 =  filtered_df1.dropna(subset=[column_name])\n",
    "        # Remove annual trends\n",
    "        y_residual = remove_annual_trends(filtered_df1,column_name)\n",
    "        # Calculate the partial correlation coefficient between the residuals of the factor column and the LUD/IOD column\n",
    "        partial_corr[column_name] = pearsonr(y_residual, filtered_df1[\"IOD\"])[0] #LUD/IOD are vegetation and insect phenology dates respectively\n",
    "\n",
    "    # Convert the partial correlation coefficients to a Series and sort it (based on absolute values)\n",
    "    partial_corr_series = pd.Series(partial_corr)\n",
    "    # Preserve the non-absolute values\n",
    "    \n",
    "    partial_corr_series = partial_corr_series.abs().sort_values(ascending=False)\n",
    "    \n",
    "    # The most correlated (the column name with the highest absolute value of the partial correlation coefficient)\n",
    "    most_influential_column = partial_corr_series.idxmax()\n",
    "\n",
    "    return most_influential_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07994702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial Correlation\n",
    "\n",
    "# Environmental factors list\n",
    "column_list =[\"fg_\",\"hu_\",\"rr_\",\"qq_\",\"tg_\",\"total_evaporation_sum_\",\"volumetric_soil_water_layer_1_\",'soil_temperature_level_1_']\n",
    "\n",
    "# Geographic Zoning\n",
    "for s in range(0,1): \n",
    "    mean_r=[]  \n",
    "    mean_r2=[] \n",
    "    for lon in range(-15,35,1):\n",
    "        for lat in range(30,75,1):\n",
    "            # Select the phenology data of the corresponding area\n",
    "            filtered_df = df.query(f'{lon+s} <= Longitude <= {lon+1+s} and {lat} <= Latitude <= {lat+1}').reset_index() \n",
    "            filtered_df = (\n",
    "                    filtered_df.groupby('species_cluster')\n",
    "                      .filter(lambda g: len(g) > 30 and g['year'].nunique() > 10)\n",
    "                )\n",
    "            number_of_categories = (filtered_df.groupby('species_cluster')\n",
    "                                    .size()\n",
    "                                    .reset_index(name='count')\n",
    "                                    .query('count > 30')\n",
    "                                    .shape[0])\n",
    "            \n",
    "            if number_of_categories>=1:\n",
    "                #Iterate over each phenological pattern\n",
    "                all_list =[]\n",
    "                species_list = filtered_df['species_cluster'].unique()\n",
    "                scaler = StandardScaler()\n",
    "                for sp in species_list:\n",
    "                    MIC_list=[] \n",
    "                    filtered_df1=filtered_df[filtered_df[\"species_cluster\"]==sp].copy()\n",
    "                    if(filtered_df1['year'].nunique()>=10): \n",
    "                        for factor in column_list:  \n",
    "                            MIC = calculate_most_influential_column(factor, filtered_df1)\n",
    "                            MIC_list.append(MIC)#Record the optimal pre-season period for each environmental factor \n",
    "                        filtered_df1 =  filtered_df1.dropna(subset=MIC_list)\n",
    "                        for fc in MIC_list:\n",
    "                            # Remove annual trends\n",
    "                            y_residual = remove_annual_trends(filtered_df1,fc)\n",
    "                            # Standardize residuals\n",
    "                            filtered_df1[fc] = scaler.fit_transform(y_residual.values.reshape(-1, 1)) \n",
    "                        pc_list =[]\n",
    "                        # Calculate partial correlation\n",
    "                        for factor in MIC_list:\n",
    "                            covar_factors = MIC_list.copy()\n",
    "                            covar_factors.remove(factor)\n",
    "                            partial_corr = pg.partial_corr(data=filtered_df1, x='LUD', y=factor, covar=covar_factors) #IOD IOD\n",
    "                            # Record the results\n",
    "                            pc_list.append([partial_corr['r'][0],partial_corr['p-val'][0]])\n",
    "                        all_list.append([sp,filtered_df1[\"order\"].unique()[0],pc_list])\n",
    "                \n",
    "                # Organize data\n",
    "                df_all = pd.DataFrame(all_list, columns=['sp', 'order', 'params'])\n",
    "                for i, fa in enumerate(column_list):\n",
    "                    df_all[[fa + 'r', fa + 'p']] = pd.DataFrame(df_all['params'].tolist(), index=df_all.index)[i].tolist()\n",
    "                # Calculate the average partial correlation coefficients for a single geographical grid\n",
    "                columns_to_average = [f\"{fa}r\" for fa in column_list]\n",
    "                mean_r.append([lon + 0.5 + s, lat + 0.5, df_all[columns_to_average].mean().tolist()])\n",
    "                # Calculate the average partial correlation coefficients (significant P<0.05) for a single geographical grid\n",
    "                mean_r2.append([lon + 0.5 + s, lat + 0.5, [df_all[df_all[f\"{fa}p\"] < 0.05][f\"{fa}r\"].mean() for fa in column_list]])\n",
    "    \n",
    "    # Organize and output data\n",
    "    all_list_grid = [item[:2] + item[2] for item in mean_r]  \n",
    "    columns = [\"lon\",\"lat\",\"fg_r\",\"hu_r\",\"rr_r\",\"qq_r\",\"tg_r\",\"total_evaporation_sum_r\",\"volumetric_soil_water_layer_1_r\",'soil_temperature_level_1_r']\n",
    "    all_list_grid = pd.DataFrame(all_list_grid, columns=columns)\n",
    "    all_list_grid.to_csv(\"...\\\\IOD_PC_n\" + str(s) + \".csv\", index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab06632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "# Environmental factors list\n",
    "column_list =[\"fg_\",\"hu_\",\"rr_\",\"qq_\",\"tg_\",\"total_evaporation_sum_\",\"volumetric_soil_water_layer_1_\",'soil_temperature_level_1_']\n",
    "\n",
    "# Geographic Zoning\n",
    "for s in range(0,1): \n",
    "    mean_r=[]  \n",
    "    for lon in range(-15,35,1):\n",
    "        for lat in range(30,75,1):\n",
    "            # Select the phenology data of the corresponding area\n",
    "            filtered_df = df.query(f'{lon+s} <= Longitude <= {lon+1+s} and {lat} <= Latitude <= {lat+1}').reset_index()  \n",
    "            filtered_df = (\n",
    "                    filtered_df.groupby('species_cluster')\n",
    "                      .filter(lambda g: len(g) > 30 and g['year'].nunique() > 10)\n",
    "                )\n",
    "            number_of_categories = (filtered_df.groupby('species_cluster')\n",
    "                                    .size()\n",
    "                                    .reset_index(name='count')\n",
    "                                    .query('count > 30')\n",
    "                                    .shape[0])\n",
    "            if number_of_categories>=1:\n",
    "                #Iterate over each phenological pattern\n",
    "                all_list =[]\n",
    "                species_list = filtered_df['species_cluster'].unique()\n",
    "                scaler = StandardScaler()\n",
    "                for sp in species_list:\n",
    "                    MIC_list=[] \n",
    "                    filtered_df1=filtered_df[filtered_df[\"species_cluster\"]==sp].copy()\n",
    "                    if(filtered_df1['year'].nunique()>=10): \n",
    "                        for factor in column_list:  \n",
    "                            MIC = calculate_most_influential_column(factor, filtered_df1)\n",
    "                            MIC_list.append(MIC)#Record the optimal pre-season period for each environmental factor \n",
    "                        filtered_df1 =  filtered_df1.dropna(subset=MIC_list)\n",
    "                        for fc in MIC_list:\n",
    "                            # Remove annual trends\n",
    "                            y_residual = remove_annual_trends(filtered_df1,fc)\n",
    "                            # Standardize residuals\n",
    "                            filtered_df1[fc] = scaler.fit_transform(y_residual.values.reshape(-1, 1)) \n",
    "                    \n",
    "                        # Ridge Regression\n",
    "                        X = filtered_df1[MIC_list]\n",
    "                        y = filtered_df1['LUD'] #IOD/IOD\n",
    "                        ridge_model = Ridge(alpha=1.0)\n",
    "                        ridge_model.fit(X, y)\n",
    "                        # Records the results\n",
    "                        pc_list = []\n",
    "                        coefficients = ridge_model.coef_[0:len(MIC_list)]\n",
    "                        for coeff in coefficients:\n",
    "                            pc_list.append([coeff])\n",
    "                        all_list.append([sp,filtered_df1[\"order\"].unique()[0],pc_list])\n",
    "                \n",
    "                # Organize data\n",
    "                df_all = pd.DataFrame(all_list, columns=['sp','order','params']) \n",
    "                for i, fa in enumerate(column_list):\n",
    "                    df_all[fa + \"r\"] = df_all['params'].apply(lambda x: x[i][0])\n",
    "\n",
    "                # Calculate the average Ridge Regression correlation coefficients for a single geographical grid\n",
    "                columns_to_average = [fa + \"r\" for fa in column_list]\n",
    "                mean_r.append([lon +0.5, lat + 0.5+ s, df_all[columns_to_average].mean().tolist()])\n",
    "    \n",
    "    #Organize and output data\n",
    "    all_list_grid = [item[:2] + item[2] for item in mean_r]  \n",
    "    columns = [\"lon\",\"lat\",\"fg_r\",\"hu_r\",\"rr_r\",\"qq_r\",\"tg_r\",\"total_evaporation_sum_r\",\"volumetric_soil_water_layer_1_r\",'soil_temperature_level_1_r']\n",
    "    all_list_grid = pd.DataFrame(all_list_grid, columns=columns)\n",
    "    all_list_grid.to_csv(\"...\\\\LUD_RC_n\" + str(s) + \".csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "\n",
    "# Environmental factors list\n",
    "column_list =[\"fg_\",\"hu_\",\"rr_\",\"qq_\",\"tg_\",\"total_evaporation_sum_\",\"volumetric_soil_water_layer_1_\",'soil_temperature_level_1_']\n",
    "\n",
    "# Geographic Zoning\n",
    "for s in range(0,1): \n",
    "    mean_r=[]  \n",
    "    for lon in range(-15,35,1):\n",
    "        for lat in range(30,75,1):\n",
    "            # Select the phenology data of the corresponding area\n",
    "            filtered_df = df.query(f'{lon+s} <= Longitude <= {lon+1+s} and {lat} <= Latitude <= {lat+1}').reset_index()  \n",
    "            filtered_df = (\n",
    "                    filtered_df.groupby('species_cluster')\n",
    "                      .filter(lambda g: len(g) > 30 and g['year'].nunique() > 10)\n",
    "                )\n",
    "            number_of_categories = (filtered_df.groupby('species_cluster')\n",
    "                                    .size()\n",
    "                                    .reset_index(name='count')\n",
    "                                    .query('count > 30')\n",
    "                                    .shape[0])\n",
    "            if number_of_categories>=1:\n",
    "                #Iterate over each phenological pattern\n",
    "                all_list =[]\n",
    "                species_list = filtered_df['species_cluster'].unique()\n",
    "                scaler = StandardScaler()\n",
    "                for sp in species_list:\n",
    "                    MIC_list=[] \n",
    "                    filtered_df1=filtered_df[filtered_df[\"species_cluster\"]==sp].copy()\n",
    "                    if(filtered_df1['year'].nunique()>=10): \n",
    "                        for factor in column_list:  \n",
    "                            MIC = calculate_most_influential_column(factor, filtered_df1)\n",
    "                            MIC_list.append(MIC) #Record the optimal pre-season period for each environmental factor \n",
    "                        filtered_df1 =  filtered_df1.dropna(subset=MIC_list)\n",
    "                        for fc in MIC_list:\n",
    "                            # Remove annual trends\n",
    "                            y_residual = remove_annual_trends(filtered_df1,fc)\n",
    "                            # Standardize residuals\n",
    "                            filtered_df1[fc] = scaler.fit_transform(y_residual.values.reshape(-1, 1)) \n",
    "                        \n",
    "                        # Random forest\n",
    "                        pc_list =[]\n",
    "                        X = filtered_df1[MIC_list]\n",
    "                        y = filtered_df1['LUD'] #IOD/IOD\n",
    "                        rf_model = RandomForestRegressor(n_estimators=100)\n",
    "                        rf_model.fit(X, y)\n",
    "                        feature_importances = rf_model.feature_importances_\n",
    "                        importances = feature_importances[:len(MIC_list)]\n",
    "                        pc_list = [[importance] for importance in importances]\n",
    "                        all_list.append([sp, filtered_df1[\"order\"].unique()[0], pc_list])\n",
    "                \n",
    "                # Organize data\n",
    "                df_all = pd.DataFrame(all_list, columns=['sp','order','params']) \n",
    "                for i, fa in enumerate(column_list):\n",
    "                    df_all[fa + \"r\"] = df_all['params'].apply(lambda x: x[i][0])\n",
    "                # Calculate the average random forest feature importance for a single geographical grid\n",
    "                columns_to_average = [fa + \"r\" for fa in column_list]\n",
    "                mean_r.append([lon + 0.5 + s, lat + 0.5, df_all[columns_to_average].mean().tolist()])\n",
    "    \n",
    "    #Organize and output data\n",
    "    all_list_grid = [item[:2] + item[2] for item in mean_r]  \n",
    "    columns = [\"lon\",\"lat\",\"fg_r\",\"hu_r\",\"rr_r\",\"qq_r\",\"tg_r\",\"total_evaporation_sum_r\",\"volumetric_soil_water_layer_1_r\",'soil_temperature_level_1_r']\n",
    "    all_list_grid = pd.DataFrame(all_list_grid, columns=columns)\n",
    "    all_list_grid.to_csv(\"...\\\\LUD_RF_r\" + str(s) + \".csv\", index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
